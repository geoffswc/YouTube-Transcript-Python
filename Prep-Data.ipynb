{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c3c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install youtube_transcript_api\n",
    "#!pip isntall pandasql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f01a80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import pandas as pd\n",
    "from pandasql import sqldf \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1937b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysqldf = lambda q: sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "771488ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b9e45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ee3b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [\n",
    "    'BDqvzFY72mg',\n",
    "    'f5nbT4xQqwI',\n",
    "    's48b9B5gd88',\n",
    "    '4eUS8trd_yI',\n",
    "    'aKW_Vsk4hzs',\n",
    "    'q53DF6ySOZg',\n",
    "    'T3-VlQu3iRM'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a371092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BDqvzFY72mg translated\n",
      "f5nbT4xQqwI translated\n",
      "s48b9B5gd88 translated\n",
      "4eUS8trd_yI translated\n"
     ]
    }
   ],
   "source": [
    "transcripts = []\n",
    "for v in links:\n",
    "    try:\n",
    "        df = pd.DataFrame(YouTubeTranscriptApi.get_transcript(v))\n",
    "        df['video_id'] = v\n",
    "        transcripts.append(df)\n",
    "        print(v, 'translated')\n",
    "    except:\n",
    "        print(v, 'failed to translate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts = pd.concat(transcripts).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3413edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts['alpha_text'] = df_transcripts.text.str.replace(\"[^a-zA-Z]\", ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1524545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "\n",
    "df_transcripts['no_stop'] = df_transcripts['alpha_text'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word.lower() not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bc033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7cbdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts['lemmatized_text'] = df_transcripts['no_stop'].apply(\n",
    "    lambda words: ' '.join(lemmatizer.lemmatize(w) for w in words.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ce8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts['row_num'] = df_transcripts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b83f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts.to_csv('transcripts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The number of cells that will be squashed into a single cell is set by the \n",
    "## ranking - for instance, to combine every 10 cells, add 9 (to offset index at 1)\n",
    "## and divide by 10 (keeping only the integer remainder)\n",
    "\n",
    "df_transcripts_m10 = pysqldf(\"\"\"\n",
    "WITH df_ranked AS\n",
    "\n",
    "(SELECT\n",
    "    *,\n",
    "    (RANK () OVER ( \n",
    "        PARTITION BY video_id\n",
    "        ORDER BY start ASC\n",
    "    ) + 9)/ 10 RNK \n",
    "FROM\n",
    "    df_transcripts\n",
    "ORDER BY row_num\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    GROUP_CONCAT(text, ' ') as text,\n",
    "    GROUP_CONCAT(alpha_text, ' ') as alpha_text,\n",
    "    GROUP_CONCAT(no_stop, ' ') as no_stop,\n",
    "    GROUP_CONCAT(lemmatized_text, ' ') as lemmatized_text,\n",
    "    MIN(start), \n",
    "    MAX(start), \n",
    "    SUM(duration), \n",
    "    video_id \n",
    "FROM df_ranked\n",
    "GROUP BY\n",
    "    rnk, video_id\n",
    "ORDER BY video_id, MIN(start)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83482438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts_m10.to_csv('transcripts_m10.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62caeaf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
