{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most relevant terms for each topic using KMeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts = pd.read_csv(\"transcripts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts['text'] = df_transcripts['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "df_transcripts['text'] = df_transcripts['text'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts['text'] = df_transcripts['text'].str.replace(\"[^\\w\\d'\\s]+\", ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_transcripts['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [word for word in df_transcripts['text'] if not word in stop and len(word) >2] \n",
    "text = [re.sub('[^a-zA-Z]', ' ', word) for word in df_transcripts['text']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(stop_words = stop, ngram_range = (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_text = tfv.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vec_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tfv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 10)\n",
    "kmeans.fit(vec_text)\n",
    "cluster_words = kmeans.cluster_centers_\n",
    "df_cluster_words = pd.DataFrame(cluster_words, columns=words).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cluster_words.iloc[0:10, 0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0\n",
      "one          0.065011\n",
      "countries    0.046566\n",
      "course       0.045828\n",
      "world        0.041901\n",
      "going        0.041706\n",
      "look         0.035687\n",
      "get          0.034797\n",
      "go           0.034541\n",
      "war          0.034068\n",
      "actually     0.033550\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "\n",
      "Document 1\n",
      "people       0.362198\n",
      "many         0.028673\n",
      "think        0.017858\n",
      "like         0.015475\n",
      "working      0.014433\n",
      "know         0.013327\n",
      "get          0.010886\n",
      "getting      0.010596\n",
      "rich         0.010496\n",
      "interests    0.010259\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "\n",
      "Document 2\n",
      "gonna         0.223932\n",
      "union         0.159861\n",
      "soviet        0.130003\n",
      "european      0.030905\n",
      "talk          0.025435\n",
      "membership    0.016111\n",
      "less          0.013773\n",
      "look          0.013525\n",
      "get           0.011969\n",
      "pressure      0.011828\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "\n",
      "Document 3\n",
      "would       0.226111\n",
      "think       0.187755\n",
      "thought     0.015108\n",
      "way         0.012828\n",
      "let         0.012222\n",
      "come        0.011906\n",
      "make        0.011155\n",
      "good        0.010401\n",
      "maybe       0.010357\n",
      "argument    0.009914\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "\n",
      "Document 4\n",
      "see         0.543809\n",
      "right       0.021995\n",
      "going       0.020936\n",
      "thursday    0.019281\n",
      "start       0.018480\n",
      "parties     0.016915\n",
      "increase    0.013605\n",
      "minute      0.012927\n",
      "people      0.012501\n",
      "gonna       0.012333\n",
      "Name: 4, dtype: float64\n",
      "\n",
      "\n",
      "Document 5\n",
      "party        0.007062\n",
      "like         0.007018\n",
      "much         0.006637\n",
      "time         0.005932\n",
      "right        0.005864\n",
      "us           0.005859\n",
      "economy      0.005786\n",
      "political    0.005703\n",
      "way          0.005416\n",
      "years        0.005251\n",
      "Name: 5, dtype: float64\n",
      "\n",
      "\n",
      "Document 6\n",
      "lot             0.446590\n",
      "people          0.035483\n",
      "wisdom          0.034105\n",
      "money           0.033690\n",
      "conventional    0.028230\n",
      "make            0.022782\n",
      "criticism       0.018720\n",
      "time            0.016971\n",
      "awful           0.016912\n",
      "spend           0.016855\n",
      "Name: 6, dtype: float64\n",
      "\n",
      "\n",
      "Document 7\n",
      "might      0.443177\n",
      "think      0.035095\n",
      "say        0.032574\n",
      "case       0.024444\n",
      "company    0.021088\n",
      "enough     0.017390\n",
      "become     0.016530\n",
      "one        0.014667\n",
      "call       0.014392\n",
      "story      0.013647\n",
      "Name: 7, dtype: float64\n",
      "\n",
      "\n",
      "Document 8\n",
      "said        0.472921\n",
      "gonna       0.021323\n",
      "back        0.021177\n",
      "actually    0.018615\n",
      "people      0.018436\n",
      "earlier     0.015586\n",
      "going       0.015370\n",
      "lawyers     0.014973\n",
      "party       0.014462\n",
      "well        0.014206\n",
      "Name: 8, dtype: float64\n",
      "\n",
      "\n",
      "Document 9\n",
      "say           0.357330\n",
      "audience      0.183459\n",
      "laughing      0.068245\n",
      "applauds      0.049688\n",
      "cheering      0.049104\n",
      "well          0.037353\n",
      "could         0.035194\n",
      "thing         0.029199\n",
      "applauding    0.027408\n",
      "people        0.027361\n",
      "Name: 9, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print('Document', i)\n",
    "    print(df_cluster_words.sort_values(i, ascending=False)[i].head(10))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 5, 8, 8], dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a prediction\n",
    "vec_text = [\"people many think like working know getting rich\",\n",
    "           \"how china cold war united states\",\n",
    "           \"political parties played blame game\",\n",
    "           \"lawsuits said lawyers actually going back earlier\",\n",
    "           \"political parties played blame game lawsuits said lawyers actually going back earlier\"]\n",
    "\n",
    "kmeans.predict(tfv.transform(vec_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
