{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most relevant terms for each topic using LDA clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts = pd.read_csv(\"transcripts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>duration</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello everybody welcome</td>\n",
       "      <td>8.060</td>\n",
       "      <td>2.660</td>\n",
       "      <td>BDqvzFY72mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>everybody today</td>\n",
       "      <td>10.720</td>\n",
       "      <td>1.613</td>\n",
       "      <td>BDqvzFY72mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great</td>\n",
       "      <td>13.404</td>\n",
       "      <td>0.916</td>\n",
       "      <td>BDqvzFY72mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>well  i'm delighted opportunity</td>\n",
       "      <td>14.320</td>\n",
       "      <td>3.540</td>\n",
       "      <td>BDqvzFY72mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>giving devane lectures</td>\n",
       "      <td>17.860</td>\n",
       "      <td>2.920</td>\n",
       "      <td>BDqvzFY72mg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text   start  duration     video_id\n",
       "0         hello everybody welcome    8.060     2.660  BDqvzFY72mg\n",
       "1                 everybody today   10.720     1.613  BDqvzFY72mg\n",
       "2                           great   13.404     0.916  BDqvzFY72mg\n",
       "3  well  i'm delighted opportunity  14.320     3.540  BDqvzFY72mg\n",
       "4          giving devane lectures   17.860     2.920  BDqvzFY72mg"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transcripts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts['text'] = df_transcripts['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "df_transcripts['text'] = df_transcripts['text'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts['text'] = df_transcripts['text'].str.replace(\"[^\\w\\d'\\s]+\", ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_transcripts['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_text = [word for word in df_transcripts['text'] if not word in stop and len(word) >2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  hello everybody welcome ',\n",
       " 'everybody today ',\n",
       " 'great ',\n",
       " \"well  i'm delighted opportunity\",\n",
       " 'giving devane lectures ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(stop_words = stop, ngram_range = (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_text = tfv.fit_transform(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tfv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '000', '10', '1000', '101', '109', '11', '11th', '12', '125']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now working through https://medium.com/@yanlinc/how-to-build-a-lda-topic-model-using-from-text-601cdcbfd3a6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=10)\n",
    "\n",
    "#https://www.kaggle.com/rajmehra03/topic-modelling-using-lda-and-lsa-in-sklearn\n",
    "lda_output = lda_model.fit_transform(vec_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0367344  0.03673116 0.03674078 ... 0.03673116 0.03673453 0.03673291]\n",
      " [0.04155443 0.04155411 0.04155764 ... 0.04155398 0.04155531 0.04155372]\n",
      " [0.54998393 0.05       0.05       ... 0.05000438 0.05       0.05      ]\n",
      " ...\n",
      " [0.03095321 0.03097081 0.03095434 ... 0.03096456 0.03095409 0.40897099]\n",
      " [0.04195617 0.39368446 0.04195536 ... 0.04195536 0.04195675 0.04195536]\n",
      " [0.04149767 0.04150554 0.04149767 ... 0.04153792 0.04149767 0.04150513]]\n"
     ]
    }
   ],
   "source": [
    "print(lda_output)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_documents = pd.DataFrame(lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.036734</td>\n",
       "      <td>0.036731</td>\n",
       "      <td>0.036741</td>\n",
       "      <td>0.036734</td>\n",
       "      <td>0.427152</td>\n",
       "      <td>0.278958</td>\n",
       "      <td>0.036751</td>\n",
       "      <td>0.036731</td>\n",
       "      <td>0.036735</td>\n",
       "      <td>0.036733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041554</td>\n",
       "      <td>0.041554</td>\n",
       "      <td>0.041558</td>\n",
       "      <td>0.041555</td>\n",
       "      <td>0.041559</td>\n",
       "      <td>0.041553</td>\n",
       "      <td>0.626003</td>\n",
       "      <td>0.041554</td>\n",
       "      <td>0.041555</td>\n",
       "      <td>0.041554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.549984</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.037015</td>\n",
       "      <td>0.037016</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>0.037026</td>\n",
       "      <td>0.666857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036650</td>\n",
       "      <td>0.036650</td>\n",
       "      <td>0.036650</td>\n",
       "      <td>0.463608</td>\n",
       "      <td>0.036650</td>\n",
       "      <td>0.036652</td>\n",
       "      <td>0.036650</td>\n",
       "      <td>0.036650</td>\n",
       "      <td>0.036650</td>\n",
       "      <td>0.243191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.036670</td>\n",
       "      <td>0.036721</td>\n",
       "      <td>0.036671</td>\n",
       "      <td>0.669921</td>\n",
       "      <td>0.036670</td>\n",
       "      <td>0.036670</td>\n",
       "      <td>0.036669</td>\n",
       "      <td>0.036669</td>\n",
       "      <td>0.036669</td>\n",
       "      <td>0.036670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.669350</td>\n",
       "      <td>0.036733</td>\n",
       "      <td>0.036734</td>\n",
       "      <td>0.036759</td>\n",
       "      <td>0.036734</td>\n",
       "      <td>0.036745</td>\n",
       "      <td>0.036733</td>\n",
       "      <td>0.036736</td>\n",
       "      <td>0.036740</td>\n",
       "      <td>0.036736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.697162</td>\n",
       "      <td>0.033648</td>\n",
       "      <td>0.033646</td>\n",
       "      <td>0.033649</td>\n",
       "      <td>0.033646</td>\n",
       "      <td>0.033647</td>\n",
       "      <td>0.033662</td>\n",
       "      <td>0.033647</td>\n",
       "      <td>0.033646</td>\n",
       "      <td>0.033648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.669906</td>\n",
       "      <td>0.036711</td>\n",
       "      <td>0.036673</td>\n",
       "      <td>0.036672</td>\n",
       "      <td>0.036672</td>\n",
       "      <td>0.036672</td>\n",
       "      <td>0.036679</td>\n",
       "      <td>0.036672</td>\n",
       "      <td>0.036672</td>\n",
       "      <td>0.036672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.699430</td>\n",
       "      <td>0.033390</td>\n",
       "      <td>0.033394</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.033394</td>\n",
       "      <td>0.033399</td>\n",
       "      <td>0.033390</td>\n",
       "      <td>0.033390</td>\n",
       "      <td>0.033393</td>\n",
       "      <td>0.033395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.036734  0.036731  0.036741  0.036734  0.427152  0.278958  0.036751   \n",
       "1  0.041554  0.041554  0.041558  0.041555  0.041559  0.041553  0.626003   \n",
       "2  0.549984  0.050000  0.050000  0.050000  0.050009  0.050000  0.050003   \n",
       "3  0.037014  0.037014  0.037015  0.037016  0.037014  0.037014  0.037014   \n",
       "4  0.036650  0.036650  0.036650  0.463608  0.036650  0.036652  0.036650   \n",
       "5  0.036670  0.036721  0.036671  0.669921  0.036670  0.036670  0.036669   \n",
       "6  0.669350  0.036733  0.036734  0.036759  0.036734  0.036745  0.036733   \n",
       "7  0.697162  0.033648  0.033646  0.033649  0.033646  0.033647  0.033662   \n",
       "8  0.669906  0.036711  0.036673  0.036672  0.036672  0.036672  0.036679   \n",
       "9  0.699430  0.033390  0.033394  0.033424  0.033394  0.033399  0.033390   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.036731  0.036735  0.036733  \n",
       "1  0.041554  0.041555  0.041554  \n",
       "2  0.050004  0.050000  0.050000  \n",
       "3  0.037017  0.037026  0.666857  \n",
       "4  0.036650  0.036650  0.243191  \n",
       "5  0.036669  0.036669  0.036670  \n",
       "6  0.036736  0.036740  0.036736  \n",
       "7  0.033647  0.033646  0.033648  \n",
       "8  0.036672  0.036672  0.036672  \n",
       "9  0.033390  0.033393  0.033395  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_documents.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0\n",
      "union 44.631182350297365\n",
      "soviet 39.76222632740541\n",
      "party 22.34158761333463\n",
      "european 20.58872893354754\n",
      "countries 19.745561598014017\n",
      "part 19.192330999721626\n",
      "left 14.151042961600218\n",
      "two 14.087844811319728\n",
      "systems 13.129011585867444\n",
      "political 12.891593513535051\n",
      "\n",
      "\n",
      "Document 1\n",
      "communist 20.712448105199602\n",
      "us 16.52534653581773\n",
      "point 14.356099508240176\n",
      "crisis 13.008710797065708\n",
      "gonna 12.856419594219364\n",
      "leadership 12.000357828466337\n",
      "party 11.96903441472972\n",
      "came 11.566601858844166\n",
      "since 11.00740735836723\n",
      "indeed 9.647301149380096\n",
      "\n",
      "\n",
      "Document 2\n",
      "might 17.916577154235224\n",
      "saying 16.073930065010853\n",
      "china 15.569717646606476\n",
      "vietnam 12.546514067650332\n",
      "basically 11.237976329419425\n",
      "people 10.486091594353057\n",
      "interest 9.581819474690212\n",
      "called 9.497123833007521\n",
      "reform 8.534647570300898\n",
      "language 8.304013360837917\n",
      "\n",
      "\n",
      "Document 3\n",
      "way 20.96988347410647\n",
      "people 18.18912158388891\n",
      "unions 15.545972152769\n",
      "even 14.76596840047766\n",
      "middle 13.56857296822916\n",
      "better 13.43391213750844\n",
      "get 13.123503181655474\n",
      "idea 12.176686621723416\n",
      "labor 11.300779506009135\n",
      "class 11.21865151461036\n",
      "\n",
      "\n",
      "Document 4\n",
      "audience 20.574519877796153\n",
      "change 13.887101326872726\n",
      "coalition 11.879171008181629\n",
      "democrats 11.83922758846875\n",
      "russian 11.502232401759116\n",
      "people 11.438886170026594\n",
      "ways 9.588220463641914\n",
      "international 9.330526726936604\n",
      "state 9.290199129900003\n",
      "different 8.805657369655721\n",
      "\n",
      "\n",
      "Document 5\n",
      "war 32.40305270294393\n",
      "world 20.611182325840332\n",
      "median 17.69434047485586\n",
      "new 16.74546648237361\n",
      "cold 16.570599769806712\n",
      "would 15.33586583431529\n",
      "voter 14.83242225789418\n",
      "could 12.739785456632339\n",
      "good 12.731782260048817\n",
      "inequality 11.916913874296881\n",
      "\n",
      "\n",
      "Document 6\n",
      "see 53.01631278353495\n",
      "course 27.322599047744713\n",
      "later 27.111451768517092\n",
      "gonna 23.0088183272417\n",
      "know 22.698027307324125\n",
      "talking 20.210233207289498\n",
      "today 12.36663893185941\n",
      "talk 12.029716892179728\n",
      "make 11.894244698147213\n",
      "people 11.478207217834106\n",
      "\n",
      "\n",
      "Document 7\n",
      "yeah 24.049147072867974\n",
      "say 21.816539509640936\n",
      "right 18.78021023529272\n",
      "said 17.515068960266614\n",
      "thought 13.325797156218956\n",
      "time 12.606837276828331\n",
      "things 12.23104141502106\n",
      "less 11.569600739094872\n",
      "far 11.44225727104283\n",
      "america 11.31267054758957\n",
      "\n",
      "\n",
      "Document 8\n",
      "look 31.074695459706675\n",
      "like 16.863460885757302\n",
      "little 15.436317146984829\n",
      "going 14.793030137637171\n",
      "sector 14.67632264962012\n",
      "think 13.64040189628687\n",
      "thinking 12.790864190059805\n",
      "foreign 11.466242094511701\n",
      "people 10.9424789579871\n",
      "went 10.600617378157489\n",
      "\n",
      "\n",
      "Document 9\n",
      "one 21.02298155631812\n",
      "first 18.98684588817214\n",
      "years 17.765069879741123\n",
      "example 14.144814542973915\n",
      "trade 13.55159767256041\n",
      "ago 13.144016521106032\n",
      "reason 12.278705391891432\n",
      "well 11.900397064059261\n",
      "another 11.58592590915948\n",
      "thing 10.968137255973815\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = tfv.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "    words_comp = dict(zip(words, comp))\n",
    "    sorted_words = sorted(words_comp.items(), reverse=True, key=lambda item: item[1])\n",
    "    print(\"Document\", i)\n",
    "    for w in sorted_words[:10]:\n",
    "        print(w[0], w[1])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02636813, 0.02636813, 0.02636813, 0.76268684, 0.02636813,\n",
       "        0.02636813, 0.02636813, 0.02636813, 0.02636813, 0.02636813],\n",
       "       [0.03664977, 0.03664977, 0.03664977, 0.03664977, 0.03664977,\n",
       "        0.03664977, 0.03664977, 0.67015211, 0.03664977, 0.03664977],\n",
       "       [0.02775566, 0.02775566, 0.02775566, 0.02775566, 0.02775566,\n",
       "        0.02775566, 0.75019904, 0.02775566, 0.02775566, 0.02775566]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a prediction# make a prediction\n",
    "vec_text = [\"people many think like working know getting rich\",\n",
    "           \"giving devane lectures\",\n",
    "           \"might saying china vietnam interested called reform\"]\n",
    "lda_model.fit_transform(tfv.transform(vec_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
