{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most relevant terms for each topic using LDA clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts = pd.read_csv(\"transcripts_m10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_transcripts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(ngram_range = (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_text = tfv.fit_transform(df_transcripts['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tfv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=10)\n",
    "lda_output = lda_model.fit_transform(vec_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(lda_output)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_documents = pd.DataFrame(lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tfv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(lda_model.components_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, comp in enumerate(lda_model.components_):\n",
    "    words_comp = dict(zip(words, comp))\n",
    "    sorted_words = sorted(words_comp.items(), reverse=True, key=lambda item: item[1])\n",
    "    print(\"Topic\", i)\n",
    "    for w in sorted_words[:10]:\n",
    "        print(w[0], w[1])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction# make a prediction\n",
    "vec_text = [\"people many think like working know getting rich\",\n",
    "           \"political parties played blame game\",\n",
    "           \"lawsuits said lawyers actually going back earlier\",\n",
    "           \"political parties played blame game lawsuits said lawyers actually going back earlier\"]\n",
    "lda_model.fit_transform(tfv.transform(vec_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view top document matches for a particular category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_documents, df_transcripts], axis=1)\n",
    "df_all.sort_values(2, ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_text = \"\"\"The Cold War was a period of global geopolitical tension and struggle for ideological and \n",
    "economic influence between the United States and the Soviet Union (USSR) and their respective allies, the \n",
    "Western Bloc and the Eastern Bloc, that started in 1947, two years after the end of World War II, and lasted \n",
    "until the fall of the Soviet Union in 1991. The term cold war is used because there was no direct fighting \n",
    "between the two superpowers, though each supported opposing sides in major regional conflicts known as proxy \n",
    "wars. Aside from the nuclear arms race starting in 1949 and conventional military deployment, the struggle for \n",
    "dominance was expressed indirectly via psychological warfare, propaganda campaigns, espionage, far-reaching \n",
    "embargoes, sports diplomacy, and technological competitions such as the Space Race.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of stop words, non-alphanumeric text, lemmatize\n",
    "def cleanDocument(text):\n",
    "    words = text.split()\n",
    "    \n",
    "    cleaned = []\n",
    "    for w in words:\n",
    "        w = re.sub(r'\\W+', '', w)\n",
    "        #print(w)\n",
    "        w = w.lower()\n",
    "        \n",
    "        w = lemmatizer.lemmatize(w)\n",
    "        \n",
    "        if w not in stop:\n",
    "            cleaned.append(w)\n",
    "            \n",
    "    return ' '.join(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pred_text = cleanDocument(pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pred_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
